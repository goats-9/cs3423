\documentclass[journal,12pt,twocolumn]{IEEEtran}
\usepackage{setspace}
\usepackage{gensymb}
\singlespacing
\usepackage[cmex10]{amsmath}
\usepackage{amsthm}
\usepackage{mathrsfs}
\usepackage{txfonts}
\usepackage{stfloats}
\usepackage{bm}
\usepackage{cite}
\usepackage{cases}
\usepackage{subfig}
\usepackage{longtable}
\usepackage{multirow}
\usepackage{enumitem}
\usepackage{mathtools}
\usepackage{tikz}
\usepackage{circuitikz}
\usepackage{verbatim}
\usepackage[breaklinks=true]{hyperref}
\usepackage{tkz-euclide} % loads  TikZ and tkz-base
\usepackage{listings}
\usepackage{color}    
\usepackage{array}    
\usepackage{longtable}
\usepackage{calc}     
\usepackage{multirow} 
\usepackage{hhline}   
\usepackage{ifthen}   
\usepackage{lscape}     
\usepackage{chngcntr}
\DeclareMathOperator*{\Res}{Res}
\renewcommand\thesection{\arabic{section}}
\renewcommand\thesubsection{\thesection.\arabic{subsection}}
\renewcommand\thesubsubsection{\thesubsection.\arabic{subsubsection}}

\renewcommand\thesectiondis{\arabic{section}}
\renewcommand\thesubsectiondis{\thesectiondis.\arabic{subsection}}
\renewcommand\thesubsubsectiondis{\thesubsectiondis.\arabic{subsubsection}}
\renewcommand\thetable{\arabic{table}}
% correct bad hyphenation here
\hyphenation{op-tical net-works semi-conduc-tor}
\def\inputGnumericTable{}                                 %%

\lstset{
language=bash,
frame=single, 
breaklines=true,
columns=fullflexible,
basicstyle=\ttfamily,
}
%\lstset{
%language=tex,
%frame=single, 
%breaklines=true
%}

\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}
\begin{document}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{problem}{Problem}
\newtheorem{proposition}{Proposition}[section]
\newtheorem{lemma}{Lemma}[section]
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{example}{Example}[section]
\newtheorem{definition}[problem]{Definition}
\newcommand{\BEQA}{\begin{eqnarray}}
\newcommand{\EEQA}{\end{eqnarray}}
\newcommand{\define}{\stackrel{\triangle}{=}}
\bibliographystyle{IEEEtran}
\providecommand{\mbf}{\mathbf}
\providecommand{\pr}[1]{\ensuremath{\Pr\left(#1\right)}}
\providecommand{\qfunc}[1]{\ensuremath{Q\left(#1\right)}}
\providecommand{\sbrak}[1]{\ensuremath{{}\left[#1\right]}}
\providecommand{\lsbrak}[1]{\ensuremath{{}\left[#1\right.}}
\providecommand{\rsbrak}[1]{\ensuremath{{}\left.#1\right]}}
\providecommand{\brak}[1]{\ensuremath{\left(#1\right)}}
\providecommand{\lbrak}[1]{\ensuremath{\left(#1\right.}}
\providecommand{\rbrak}[1]{\ensuremath{\left.#1\right)}}
\providecommand{\cbrak}[1]{\ensuremath{\left\{#1\right\}}}
\providecommand{\lcbrak}[1]{\ensuremath{\left\{#1\right.}}
\providecommand{\rcbrak}[1]{\ensuremath{\left.#1\right\}}}
\theoremstyle{remark}
\newtheorem{rem}{Remark}
\newcommand{\sgn}{\mathop{\mathrm{sgn}}}
\providecommand{\abs}[1]{\left\vert#1\right\vert}
\providecommand{\res}[1]{\Res\displaylimits_{#1}} 
\providecommand{\norm}[1]{\left\lVert#1\right\rVert}
\providecommand{\mtx}[1]{\mathbf{#1}}
\providecommand{\mean}[1]{E\left[ #1 \right]}   
\providecommand{\fourier}{\overset{\mathcal{F}}{ \rightleftharpoons}}
\providecommand{\system}[1]{\overset{\mathcal{#1}}{ \longleftrightarrow}}
\newcommand{\solution}{\noindent \textbf{Solution: }}
\newcommand{\cosec}{\,\text{cosec}\,}
\providecommand{\dec}[2]{\ensuremath{\overset{#1}{\underset{#2}{\gtrless}}}}
\newcommand{\myvec}[1]{\ensuremath{\begin{pmatrix}#1\end{pmatrix}}}
\newcommand{\mydet}[1]{\ensuremath{\begin{vmatrix}#1\end{vmatrix}}}
\renewcommand{\vec}[1]{\boldsymbol{\mathbf{#1}}}
\def\putbox#1#2#3{\makebox[0in][l]{\makebox[#1][l]{}\raisebox{\baselineskip}[0in][0in]{\raisebox{#2}[0in][0in]{#3}}}}
     \def\rightbox#1{\makebox[0in][r]{#1}}
     \def\centbox#1{\makebox[0in]{#1}}
     \def\topbox#1{\raisebox{-\baselineskip}[0in][0in]{#1}}
     \def\midbox#1{\raisebox{-0.5\baselineskip}[0in][0in]{#1}}

\vspace{3cm}
\title{Overview of Lexical Analyzer}
\author{Gautam Singh\\CS21BTECH11018}
\maketitle
\tableofcontents
\bigskip

This document provides a brief overview, implementation details and challenges
in creating the given lexical analyzer (LA), which lexes a program in an
imaginary source language, writes the list of tokens encountered along with
their type in one file, while also writing an almost equivalent C program in
another file.

\section{Building and Usage}

To build the lexical analyzer from the \texttt{lex} source code, enter the following
commands at a terminal window.

\begin{lstlisting}
lex lex.l # flex may also be used
gcc -O2 -lfl lex.yy.c 
\end{lstlisting}

This will generate an executable file \texttt{a.out}, which is the LA.
To run the LA on any select testcase, enter the following.

\begin{lstlisting}
./a.out testcase.txt tokens.txt c.txt
\end{lstlisting}

where paths of the files are relative to the executable.

\section{Implementation Details}
The following are some important implementation details of the LA, along with
the motivations behind choosing them. The lex source code has more verbose
details related to implementation.
\begin{enumerate}
    \item A regular expression for delimiters, letters, special characters and
    digits have been specified in the regular definitions section to make it
    easier to refer in the rules section of the code, and also to create other
    complex regular expression definitions such as whitespaces (\texttt{ws}) and
    numbers (\texttt{number} and \texttt{posint}).
    \item To identify string and character constants, even those with escaped
    sequences, the \texttt{char} regular definition has been defined in the
    given way, considering escape and non-escape sequences.
    \item The main use of the regular definition \texttt{posint} is for the
    program point labels (abbreviated to \texttt{pp}) in the language to be
    lexed.
    \item The tokens encountered sequentially are also stored in a doubly linked
    list. Each node of the linked list represents a single token and contains
    the following components.
    \begin{enumerate}
        \item Pointers to nodes to the left and right of it.
        \item Lexeme in source language, and equivalent lexeme in C language.
        \item Type of the lexeme.
    \end{enumerate}
    \item Two reasons for using a doubly linked list are as follows.
    \begin{enumerate}
        \item The operator \texttt{\_} is equivalent to \texttt{pow()} in C.
        Thus, we require both operands of this binary operator. This is quite
        simple to handle with a doubly linked list, where we can refer to tokens
        before and after the operator.
        \item To generate C code appropriately, we require to check whether
        there is a \texttt{jump to} (equivalent to \texttt{goto} in C) precedes
        a label token. If so, then we need to add it to the program, otherwise
        ignore it.
    \end{enumerate}
    \item Another issue with the label tokens in the source language is that we
    require to make one prior pass to find which labels should be included in
    the C file. 
    
    This has been implemented using an integer array as a direct addressing
    table, whose element at an index \texttt{i} is 1 if the label at line
    \texttt{i} has been referenced, and 0 otherwise.
    \item The square brackets have two meanings based on the context they are
    used in the source language. A boolean flag variable \texttt{yycondfl} is
    used to differentiate the use.
\end{enumerate}

\section{Implementation Issues}
Some of the implementation issues and shortcomings of the LA are described
below.
\begin{enumerate}
    \item The LA keeps reallocating the direct addressing dynamically, based on
    the number of lines being lexed. To prevent this, one more pass would be
    needed to find the number of lines, which is undesirable.
    \item The LA cannot catch all the errors in the program point labels at the
    start of each line, lexing them as identifiers instead. Such a check would
    have to be left to the semantic analyzer in a compiler pipeline.
    \item The LA cannot generate indented C source code. Thankfully, indentation
    does not affect the compilation process in C, and is only for readability. 
\end{enumerate}
\end{document}
